{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6efc180-828a-40b7-9d1d-e8a8ba85763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "#import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv('data/housing.csv')\n",
    "selected_houses = ['<1H OCEAN', 'INLAND']\n",
    "df = data[data['ocean_proximity'].isin(selected_houses)].copy()\n",
    "\n",
    "df['ocean_proximity'].replace({'<1H OCEAN':'LT 1H OCEAN'}, inplace=True)\n",
    "df.isna().sum()[df.isna().sum()>0]\n",
    "\n",
    "df['total_bedrooms'].fillna(0, inplace=True)\n",
    "\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = np.log1p(df_train.median_house_value.values)\n",
    "y_val = np.log1p(df_val.median_house_value.values)\n",
    "y_test = np.log1p(df_test.median_house_value.values)\n",
    "\n",
    "del df_train['median_house_value']\n",
    "del df_val['median_house_value']\n",
    "del df_test['median_house_value']\n",
    "\n",
    "train_dicts = df_train.to_dict(orient='records')\n",
    "val_dicts = df_val.to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "X_val = dv.transform(val_dicts)\n",
    "\n",
    "\n",
    "dt = DecisionTreeRegressor(max_depth=1)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "print(\"ocean_proximity is used for splitting the data\")\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=10, random_state=1, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_val)\n",
    "np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "scores = []\n",
    "\n",
    "for n in tqdm(range(10, 201, 10)):\n",
    "    rf = RandomForestRegressor(n_estimators=n, random_state=1, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_val)\n",
    "    score = round(np.sqrt(mean_squared_error(y_val, y_pred)),3)\n",
    "    scores.append((n, score))\n",
    "    time.sleep(0.1)\n",
    "\n",
    "df_scores = pd.DataFrame(scores, columns=['n_estimators', 'rmse'])\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(df_scores.n_estimators, df_scores.rmse.round(3))\n",
    "\n",
    "\n",
    "scores = []\n",
    "\n",
    "for d in tqdm([10, 15, 20, 25]):\n",
    "    rf = RandomForestRegressor(n_estimators=0,\n",
    "                               max_depth=d,\n",
    "                               random_state=1, n_jobs=-1,\n",
    "                               warm_start=True)\n",
    "    for n in tqdm(range(10, 201, 10)):\n",
    "        rf.n_estimators = n\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_val)\n",
    "        score = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        scores.append((d, n, score))\n",
    "    time.sleep(0.1)\n",
    "\n",
    "columns = ['max_depth', 'n_estimators', 'rmse']\n",
    "df_scores = pd.DataFrame(scores, columns=columns)\n",
    "\n",
    "for d in [10, 15, 20, 25]:\n",
    "    df_subset = df_scores[df_scores.max_depth == d]\n",
    "    plt.plot(df_subset.n_estimators, df_subset.rmse, label=d)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=10, max_depth=20, \n",
    "                           random_state=1, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "rf.feature_importances_\n",
    "\n",
    "df_importances = pd.DataFrame()\n",
    "df_importances['feature'] = dv.get_feature_names_out()\n",
    "df_importances['importance'] = rf.feature_importances_\n",
    "df_importances\n",
    "\n",
    "df_importances.sort_values(by='importance', ascending=False).head()\n",
    "\n",
    "features = dv.get_feature_names_out()\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=list(features))\n",
    "dval = xgb.DMatrix(X_val, label=y_val, feature_names=list(features))\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dval, 'val')]\n",
    "\n",
    "def parse_xgb_output(output):\n",
    "    results = []\n",
    "\n",
    "    for line in output.stdout.strip().split('\\n'):\n",
    "        it_line, train_line, val_line = line.split('\\t')\n",
    "        it = int(it_line.strip('[]'))\n",
    "        train = float(train_line.split(':')[1])\n",
    "        val = float(val_line.split(':')[1])\n",
    "        results.append((it, train, val))\n",
    "    \n",
    "    columns = ['num_iter', 'train_auc', 'val_auc']\n",
    "    df_results = pd.DataFrame(results, columns=columns)\n",
    "    return df_results\n",
    "\n",
    "scores = {}\n",
    "\n",
    "%%capture output\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=100, verbose_eval=5, evals=watchlist)\n",
    "\n",
    "scores['eta=0.3'] = parse_xgb_output(output)\n",
    "\n",
    "%%capture output\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.1, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=100, verbose_eval=5, evals=watchlist)\n",
    "\n",
    "scores['eta=0.1'] = parse_xgb_output(output)\n",
    "plt.plot(scores['eta=0.1'].num_iter, scores['eta=0.1'].val_auc, label='0.1')\n",
    "plt.plot(scores['eta=0.3'].num_iter, scores['eta=0.3'].val_auc, label='0.3')\n",
    "plt.legend()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
